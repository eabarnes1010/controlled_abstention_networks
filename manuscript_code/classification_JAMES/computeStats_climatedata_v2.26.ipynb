{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Abstention Loss\n",
    "author: Elizabeth A. Barnes, Randal J. Barnes\n",
    "date: February 23, 2021\n",
    "\n",
    "* based on Thulasidasan, S., T. Bhattacharya, J. Bilmes, G. Chennupati, and J. Mohd-Yusof, 2019: Combating Label Noise in Deep Learning Using Abstention. arXiv [stat.ML],.\n",
    "* thesis: https://digital.lib.washington.edu/researchworks/handle/1773/45781\n",
    "* code base is here: https://github.com/thulas/dac-label-noise/blob/master/dac_loss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version = 3.7.9 (default, Aug 31 2020, 07:22:35) \n",
      "[Clang 10.0.0 ]\n",
      "tf.version.VERSION = 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import random\n",
    "import xarray as xr\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "from collections import Counter\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import seaborn as sns\n",
    "import palettable\n",
    "import pprint\n",
    "\n",
    "import metrics\n",
    "import climatedata\n",
    "import plots\n",
    "import network\n",
    "import experiments\n",
    "\n",
    "import imp\n",
    "imp.reload(experiments)\n",
    "imp.reload(plots)\n",
    "\n",
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "dpiFig = 300.\n",
    "\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "tf.print(f\"sys.version = {sys.version}\", output_stream=sys.stdout)\n",
    "tf.print(f\"tf.version.VERSION = {tf.version.VERSION}\", output_stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32,\n",
      " 'cutoff': 0.5,\n",
      " 'foo_region': 'nhENSO',\n",
      " 'hiddens': [50, 25],\n",
      " 'loss': 'NotWrongLoss',\n",
      " 'lr_init': 0.001,\n",
      " 'nSamples': 18000,\n",
      " 'np_seed': 99,\n",
      " 'numClasses': 50,\n",
      " 'nupd': 6,\n",
      " 'prNoise': 1.0,\n",
      " 'simple_data': '15x60',\n",
      " 'spinup': 0,\n",
      " 'undersample': False,\n",
      " 'updater': 'Colorado'}\n"
     ]
    }
   ],
   "source": [
    "# DATA_NAME = 'badClasses0' #done\n",
    "# DATA_NAME = 'badClasses1' # done\n",
    "# DATA_NAME = 'mixedLabels2' #done\n",
    "# DATA_NAME = 'mixedLabels3' # done\n",
    "# DATA_NAME = 'tranquilFOO10' #done\n",
    "# DATA_NAME = 'tranquilFOO12' # done\n",
    "# DATA_NAME = 'tranquilFOO17' #done\n",
    "# DATA_NAME = 'tranquilFOO18' # done\n",
    "# DATA_NAME = 'tranquilFOO19' #done \n",
    "# DATA_NAME = 'tranquilFOO20' #done\n",
    "# DATA_NAME = 'tranquilFOO22' #done\n",
    "DATA_NAME = 'tranquilFOO23'\n",
    "\n",
    "EXPINFO = experiments.define_experiments(DATA_NAME)\n",
    "pprint.pprint(EXPINFO, width=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP_SEED = 99\n",
    "np.random.seed(NP_SEED)\n",
    "tf.random.set_seed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_ipynb():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if 'IPKernelApp' not in get_ipython().config:  # pragma: no cover\n",
    "            mpl.use('Agg')            \n",
    "            return False\n",
    "    except:\n",
    "        mpl.use('Agg')        \n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp_name(loss, data_name, extra_text = ''):\n",
    "    # set experiment name\n",
    "    if loss == 'DNN':\n",
    "        EXP_NAME = (\n",
    "            data_name\n",
    "            + '_DNN'\n",
    "            + '_prNoise' + str(PR_NOISE)\n",
    "            + '_networkSeed' + str(NETWORK_SEED)\n",
    "            + '_npSeed' + str(NP_SEED)\n",
    "        )                \n",
    "    else:\n",
    "        EXP_NAME = (\n",
    "            data_name\n",
    "            + '_' + loss\n",
    "            + '_' + UPDATER\n",
    "            + '_abstSetpoint' + str(setpoint)\n",
    "            + '_prNoise' + str(PR_NOISE)\n",
    "            + '_networkSeed' + str(NETWORK_SEED)\n",
    "            + '_npSeed' + str(NP_SEED)\n",
    "    )\n",
    "\n",
    "    return EXP_NAME + extra_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frac_correct(y_true,y_pred):\n",
    "    icorr = np.where(y_pred - y_true == 0)[0]\n",
    "    if(len(y_true)==0):\n",
    "        return 0., icorr\n",
    "    else:\n",
    "        return len(icorr)/len(y_true), icorr\n",
    "\n",
    "def get_acc_stats(onehotlabels, y_pred, tranquil, abstain, dnn=False):\n",
    "    \n",
    "    cat_pred = np.argmax(y_pred,axis=-1)\n",
    "    cat_true = np.argmax(onehotlabels,axis=-1)\n",
    "\n",
    "    if(dnn is True):\n",
    "        max_logits = np.max(y_pred,axis=-1)\n",
    "        i_cover = np.where(max_logits >= np.percentile(max_logits, 100.*abstain))[0]\n",
    "    else:\n",
    "        i_cover = np.where(cat_pred != abstain)[0]        \n",
    "    \n",
    "    acc, j_corr = get_frac_correct(cat_true[i_cover],cat_pred[i_cover])\n",
    "    n = len(i_cover)\n",
    "    n_corr = len(j_corr)\n",
    "    n_tr_corr = np.sum(tranquil[i_cover][j_corr])\n",
    "    n_tr = np.sum(tranquil[i_cover])\n",
    "\n",
    "    i_tr = np.where(tranquil[i_cover]==1)[0]\n",
    "    acc_tr, __ = get_frac_correct(cat_true[i_cover][i_tr], cat_pred[i_cover][i_tr])\n",
    "\n",
    "    i_tr = np.where(tranquil[i_cover]==0)[0]\n",
    "    acc_ntr, __ = get_frac_correct(cat_true[i_cover][i_tr], cat_pred[i_cover][i_tr])\n",
    "\n",
    "    return acc, acc_tr, acc_ntr, n, n_tr, n_tr_corr, n_corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST shape = (50000, 15, 60)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "if 'SSTrand' not in globals():\n",
    "    try:\n",
    "        SIMPLE_DATA = EXPINFO['simple_data']\n",
    "    except KeyError:\n",
    "        SIMPLE_DATA = False\n",
    "\n",
    "    try:\n",
    "        REGION_NAME = EXPINFO['foo_region']\n",
    "    except KeyError:\n",
    "        REGION_NAME = 'ENSO'\n",
    "        \n",
    "    if(SIMPLE_DATA==True):\n",
    "        SSTrand, y, lat, lon = climatedata.load_simpledata(size='15x60')\n",
    "    elif(SIMPLE_DATA==False):\n",
    "        SSTrand, y, lat, lon = climatedata.load_data()\n",
    "    else:\n",
    "        SSTrand, y, lat, lon = climatedata.load_simpledata(size=SIMPLE_DATA)\n",
    "\n",
    "lat = np.squeeze(lat)\n",
    "lon = np.squeeze(lon)\n",
    "print('SST shape = ' + str(np.shape(SSTrand)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region shape = 1 x 15\n",
      "\n",
      "----Mislabeled----\n",
      "# tranquil = 5227 out of 18000 samples\n",
      "percent tranquil = 29.0%\n",
      "tranquil mislabeled = 0.0%\n",
      "non-tranquil mislabeled = 100.0%\n",
      "total mislabeled = 71.0%\n",
      "----Training----\n",
      "(8000, 15, 60)\n",
      "(8000, 1)\n",
      "(8000,)\n",
      "----Validation----\n",
      "(5000, 15, 60)\n",
      "(5000, 1)\n",
      "(5000,)\n",
      "----Testing----\n",
      "(5000, 15, 60)\n",
      "(5000, 1)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "imp.reload(climatedata)\n",
    "np.random.seed(NP_SEED)\n",
    "\n",
    "NLABEL = EXPINFO['numClasses']\n",
    "NSAMPLES = EXPINFO['nSamples']\n",
    "PR_NOISE = EXPINFO['prNoise']\n",
    "CUTOFF = EXPINFO['cutoff']\n",
    "UNDERSAMPLE = EXPINFO['undersample']\n",
    "\n",
    "#----------------------------\n",
    "# get training data\n",
    "X, y_cat, tranquil, corrupt, y_perc = climatedata.add_noise(data_name=DATA_NAME, \n",
    "                                                   X=SSTrand[:NSAMPLES], \n",
    "                                                   y=y[:NSAMPLES], \n",
    "                                                   lat=lat, \n",
    "                                                   lon=lon, \n",
    "                                                   pr_noise=PR_NOISE, \n",
    "                                                   nlabel=NLABEL, \n",
    "                                                   cutoff=CUTOFF,\n",
    "                                                   region_name=REGION_NAME,                                                            \n",
    "                                                  )\n",
    "data_train, data_val, data_test = climatedata.split_data(X, y_cat, tranquil, corrupt)\n",
    "X_train, y_train, tr_train, cr_train = data_train\n",
    "X_test, y_test, tr_test, cr_test = data_test\n",
    "\n",
    "#----------------------------\n",
    "# undersample the data\n",
    "if UNDERSAMPLE:\n",
    "    print('----Training----')\n",
    "    X_train, y_train, tr_train = climatedata.undersample(X_train, y_train, tr_train) # training data\n",
    "    print('total samples = ' + str(np.shape(X_train)[0]))    \n",
    "    print('----Testing----')\n",
    "    X_test, y_test, tr_test = climatedata.undersample(X_test, y_test, tr_test) # testing data\n",
    "    print('total samples = ' + str(np.shape(X_test)[0]))            \n",
    "    \n",
    "# process data for training\n",
    "X_train_std, onehotlabels, X_test_std, onehotlabels_test, xmean, xstd = climatedata.preprocess_data(X_train, y_train, X_test, y_test, NLABEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(metrics)\n",
    "LOSS = EXPINFO['loss']\n",
    "UPDATER = EXPINFO['updater']\n",
    "REWRITE = False\n",
    "EXTRA_TEXT = ''\n",
    "#---------------------\n",
    "# Set parameters\n",
    "hiddens = EXPINFO['hiddens']\n",
    "SPINUP_EPOCHS = EXPINFO['spinup']\n",
    "BATCH_SIZE = EXPINFO['batch_size']\n",
    "N_EPOCHS = 200\n",
    "lr_epoch_bound = 10000\n",
    "RIDGE = 0.\n",
    "DNN_EPOCHS = 999\n",
    "DAC_EPOCHS = 999\n",
    "#---------------------\n",
    "DNN_model = network.defineNN(hiddens, \n",
    "                             input_shape=X_train_std.shape[1], \n",
    "                             output_shape=NLABEL, \n",
    "                             ridge_penalty=RIDGE, \n",
    "                             act_fun='relu', \n",
    "                             network_seed=99)\n",
    "DAC_model = network.defineNN(hiddens, \n",
    "                             input_shape=X_train_std.shape[1], \n",
    "                             output_shape=NLABEL+1, \n",
    "                             ridge_penalty=RIDGE, \n",
    "                             act_fun='relu', \n",
    "                             network_seed=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise ValueError('here')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare all stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network seed 0 of 49\n",
      "network seed 1 of 49\n",
      "network seed 2 of 49\n",
      "network seed 3 of 49\n",
      "network seed 4 of 49\n",
      "network seed 5 of 49\n",
      "network seed 6 of 49\n",
      "network seed 7 of 49\n",
      "network seed 8 of 49\n",
      "network seed 9 of 49\n",
      "network seed 10 of 49\n",
      "network seed 11 of 49\n",
      "network seed 12 of 49\n",
      "network seed 13 of 49\n",
      "network seed 14 of 49\n",
      "network seed 15 of 49\n",
      "network seed 16 of 49\n",
      "network seed 17 of 49\n",
      "network seed 18 of 49\n",
      "network seed 19 of 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eabarnes/opt/anaconda3/envs/env-tf2.4/lib/python3.7/site-packages/ipykernel_launcher.py:112: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network seed 20 of 49\n",
      "network seed 21 of 49\n",
      "network seed 22 of 49\n",
      "network seed 23 of 49\n",
      "network seed 24 of 49\n",
      "network seed 25 of 49\n",
      "network seed 26 of 49\n",
      "network seed 27 of 49\n",
      "network seed 28 of 49\n",
      "network seed 29 of 49\n",
      "network seed 30 of 49\n",
      "network seed 31 of 49\n",
      "network seed 32 of 49\n",
      "network seed 33 of 49\n",
      "network seed 34 of 49\n",
      "network seed 35 of 49\n",
      "network seed 36 of 49\n",
      "network seed 37 of 49\n",
      "network seed 38 of 49\n",
      "network seed 39 of 49\n",
      "network seed 40 of 49\n",
      "network seed 41 of 49\n",
      "network seed 42 of 49\n",
      "network seed 43 of 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eabarnes/opt/anaconda3/envs/env-tf2.4/lib/python3.7/site-packages/ipykernel_launcher.py:83: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network seed 44 of 49\n",
      "network seed 45 of 49\n",
      "network seed 46 of 49\n",
      "network seed 47 of 49\n",
      "network seed 48 of 49\n",
      "network seed 49 of 49\n",
      "computation done.\n",
      "plot done.\n"
     ]
    }
   ],
   "source": [
    "approach_dic = {'DNN':'', \n",
    "                'DAC':'', \n",
    "#                 'DNN-DNN':'_postDNN-DNN', \n",
    "#                 'DAC-DNN':'_postDAC-DNN', \n",
    "                'ORACLE':'_oracle', \n",
    "#                 'SELENE':'_selene'\n",
    "               }\n",
    "abstain_setpoint = np.around(np.arange(0., 1.01, .01), 3)\n",
    "seed_vector = np.arange(0,50)\n",
    "\n",
    "df = pd.DataFrame(columns=('epochs',\n",
    "                               'network_seed',\n",
    "                               'np_seed',\n",
    "                               'app_type',\n",
    "                               'setpoint',\n",
    "                               'frac_abstain',\n",
    "                               'coverage',\n",
    "                               'acc',\n",
    "                               'acc_tr',\n",
    "                               'acc_ntr',\n",
    "                               'n_cover',\n",
    "                               'n_tr',\n",
    "                               'n_tr_corr',\n",
    "                               'n_corr',\n",
    "                               'frac_tr',                               \n",
    "                               'frac_corr_tr',\n",
    "                               'acc_portion_tr',\n",
    "                               'acc_portion_ntr',\n",
    "                               'perf_frac_tr',                               \n",
    "                              )) \n",
    "curr_seed = -999\n",
    "for NETWORK_SEED in seed_vector:  \n",
    "        \n",
    "    for setpoint in abstain_setpoint:\n",
    "        for app in approach_dic.keys():\n",
    "\n",
    "            #-------------------\n",
    "            # get model names\n",
    "            if(app=='DNN' or app=='ORACLE' or app=='SELENE'):\n",
    "                EXP_NAME = get_exp_name(loss = 'DNN', data_name=DATA_NAME, extra_text=approach_dic[app])\n",
    "            elif(app=='DAC'):\n",
    "                EXP_NAME = get_exp_name(loss = LOSS, data_name=DATA_NAME, extra_text = approach_dic[app])\n",
    "            elif(app=='DNN-DNN' or app=='DAC-DNN'):\n",
    "                EXP_NAME = get_exp_name(loss = 'DNN', data_name=DATA_NAME, extra_text=approach_dic[app])\n",
    "                i = EXP_NAME.find('prNoise')\n",
    "                EXP_NAME = EXP_NAME[:i] + 'abstSetpoint' + str(setpoint) + '_' + EXP_NAME[i:]\n",
    "            else:\n",
    "                raise ValueError('no such approach')\n",
    "            model_file = 'saved_models/model_' +  EXP_NAME + '.h5'\n",
    "            \n",
    "            #check for the model file, skip if it does not exist\n",
    "            if(os.path.exists(model_file)==False):\n",
    "                continue\n",
    "            if(curr_seed!=NETWORK_SEED):\n",
    "                print('network seed ' + str(NETWORK_SEED) + ' of ' + str(seed_vector[-1]))\n",
    "                curr_seed = NETWORK_SEED\n",
    "            \n",
    "            if(app=='DAC'):\n",
    "                DAC_model.load_weights(model_file)\n",
    "                y_pred = DAC_model.predict(X_test_std)\n",
    "                abst = np.argmax(y_pred,axis=-1)\n",
    "                frac_abstain = len(np.where(abst==NLABEL)[0])/np.shape(y_pred)[0]  # compute abstention fraction\n",
    "                acc, acc_tr, acc_ntr, n_cover, n_tr, n_tr_corr, n_corr = get_acc_stats(onehotlabels=onehotlabels_test, \n",
    "                                                                    y_pred=y_pred, \n",
    "                                                                    tranquil=tr_test, \n",
    "                                                                    abstain=NLABEL,\n",
    "                                                                    dnn=False)             \n",
    "                df1 = pd.DataFrame({'epochs': DNN_EPOCHS,\n",
    "                                'network_seed': NETWORK_SEED, \n",
    "                                'np_seed': NP_SEED, \n",
    "                                'app_type':app, \n",
    "                                'setpoint': setpoint, \n",
    "                                'frac_abstain': frac_abstain, \n",
    "                                'coverage':100.*(1.-frac_abstain), \n",
    "                                'acc': acc,\n",
    "                                'acc_tr':acc_tr,\n",
    "                                'acc_ntr':acc_ntr,\n",
    "                                'n_cover':n_cover,\n",
    "                                'n_tr':n_tr,\n",
    "                                'n_tr_corr':n_tr_corr,\n",
    "                                'n_corr':n_corr,\n",
    "                                'frac_tr':n_tr/n_cover,\n",
    "                                'frac_corr_tr':n_tr_corr/n_corr,\n",
    "                                'acc_portion_tr':n_tr_corr/n_cover,\n",
    "                                'acc_portion_ntr':(n_corr-n_tr_corr)/n_cover,                                    \n",
    "                                'perf_frac_tr':np.minimum( 1., np.sum(tr_test)/ n_cover)\n",
    "                               },index=[0])                \n",
    "                df = df.append(df1,ignore_index = True)\n",
    "            else:    \n",
    "                DNN_model.load_weights(model_file)\n",
    "                y_pred = DNN_model.predict(X_test_std)                \n",
    "                acc, acc_tr, acc_ntr, n_cover, n_tr, n_tr_corr, n_corr = get_acc_stats(onehotlabels=onehotlabels_test, \n",
    "                                                                                       y_pred=y_pred,\n",
    "                                                                                       tranquil=tr_test,\n",
    "                                                                                       abstain=setpoint,\n",
    "                                                                                       dnn=True)       \n",
    "                df1 = pd.DataFrame({'epochs': DAC_EPOCHS,\n",
    "                                'network_seed': NETWORK_SEED, \n",
    "                                'np_seed': NP_SEED, \n",
    "                                'app_type':app, \n",
    "                                'setpoint': setpoint, \n",
    "                                'frac_abstain': setpoint, \n",
    "                                'coverage':100.*(1.-setpoint), \n",
    "                                'acc': acc,\n",
    "                                'acc_tr':acc_tr,\n",
    "                                'acc_ntr':acc_ntr,\n",
    "                                'n_cover':n_cover,\n",
    "                                'n_tr':n_tr,\n",
    "                                'n_tr_corr':n_tr_corr,\n",
    "                                'n_corr':n_corr,\n",
    "                                'frac_tr':n_tr/n_cover,\n",
    "                                'frac_corr_tr':n_tr_corr/n_corr,\n",
    "                                'acc_portion_tr':n_tr_corr/n_cover,\n",
    "                                'acc_portion_ntr':(n_corr-n_tr_corr)/n_cover,\n",
    "                                'perf_frac_tr':np.minimum( 1., np.sum(tr_test)/ n_cover)\n",
    "                               },index=[0])\n",
    "                df = df.append(df1,ignore_index = True)\n",
    "#----------------------------------------------------------            \n",
    "savename = (DATA_NAME\n",
    "           + '_' + LOSS\n",
    "           + '_npSeed'\n",
    "           + str(NP_SEED)\n",
    "           )\n",
    "df.to_pickle('predictions/' + savename + '.pkl')\n",
    "print('computation done.')\n",
    "\n",
    "plots.plot_stats_comparisons(df, savename=DATA_NAME, lines=True, shades=True)                \n",
    "plt.savefig('figures/summary_plots/' \n",
    "            + '/statsComparisons_' \n",
    "            + savename\n",
    "            +'.png',dpi=dpiFig)      \n",
    "plt.close()\n",
    "print('plot done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare stats on samples on which the DAC did not abstain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5ddb0c2f45ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'here'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: here"
     ]
    }
   ],
   "source": [
    "raise ValueError('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noabs = pd.DataFrame(columns=('epochs',\n",
    "                               'network_seed',\n",
    "                               'np_seed',\n",
    "                               'app_type',\n",
    "                               'setpoint',\n",
    "                               'frac_abstain',\n",
    "                               'coverage',\n",
    "                               'acc',\n",
    "                               'acc_tr',\n",
    "                               'acc_ntr',\n",
    "                               'n_cover',\n",
    "                               'n_tr',\n",
    "                               'n_tr_corr',\n",
    "                               'n_corr',\n",
    "                               'frac_tr',                               \n",
    "                               'frac_corr_tr',\n",
    "                               'acc_portion_tr',\n",
    "                               'acc_portion_ntr',                           \n",
    "                               'perf_frac_tr',                               \n",
    "                              )) \n",
    "\n",
    "curr_seed = -999\n",
    "for NETWORK_SEED in seed_vector:  \n",
    "    for setpoint in abstain_setpoint:\n",
    "        i_dac_abstain = []\n",
    "        for app in approach_dic.keys():\n",
    "\n",
    "            #-------------------\n",
    "            # get model names\n",
    "            if(app=='DNN' or app=='ORACLE' or app=='SELENE'):\n",
    "                EXP_NAME = get_exp_name(loss = 'DNN', data_name=DATA_NAME, extra_text=approach_dic[app])\n",
    "            elif(app=='DAC'):\n",
    "                EXP_NAME = get_exp_name(loss = LOSS, data_name=DATA_NAME, extra_text = approach_dic[app])\n",
    "            elif(app=='DNN-DNN' or app=='DAC-DNN'):\n",
    "                EXP_NAME = get_exp_name(loss = 'DNN', data_name=DATA_NAME, extra_text=approach_dic[app])\n",
    "                i = EXP_NAME.find('prNoise')\n",
    "                EXP_NAME = EXP_NAME[:i] + 'abstSetpoint' + str(setpoint) + '_' + EXP_NAME[i:]\n",
    "            else:\n",
    "                raise ValueError('no such approach')\n",
    "            model_file = 'saved_models/model_' +  EXP_NAME + '.h5'\n",
    "            \n",
    "            #check for the model file, skip if it does not exist\n",
    "            if(os.path.exists(model_file)==False):\n",
    "                continue\n",
    "            if(curr_seed!=NETWORK_SEED):\n",
    "                print('network seed ' + str(NETWORK_SEED) + ' of ' + str(seed_vector[-1]))\n",
    "                curr_seed = NETWORK_SEED\n",
    "                \n",
    "            \n",
    "            if(app=='DAC'):\n",
    "                DAC_model.load_weights(model_file)\n",
    "                y_pred = DAC_model.predict(X_test_std)\n",
    "                abst = np.argmax(y_pred,axis=-1)\n",
    "                i_dac_abstain = np.where(abst==NLABEL)[0]\n",
    "                frac_abstain = len(np.where(abst==NLABEL)[0])/np.shape(y_pred)[0]  # compute abstention fraction\n",
    "            else:\n",
    "                DNN_model.load_weights(model_file)\n",
    "                y_pred = DNN_model.predict(X_test_std)     \n",
    "                y_new_pred = np.append(y_pred,np.zeros([len(y_pred),1]),1)\n",
    "                y_new_pred[i_dac_abstain,:] = 0.\n",
    "                y_new_pred[i_dac_abstain,-1] = 1.\n",
    "                y_pred = y_new_pred\n",
    "                abst = np.argmax(y_pred,axis=-1)                \n",
    "                frac_abstain = len(np.where(abst==NLABEL)[0])/np.shape(y_pred)[0]  # compute abstention fraction\n",
    "                \n",
    "            acc, acc_tr, acc_ntr, n_cover, n_tr, n_tr_corr, n_corr = get_acc_stats(onehotlabels=onehotlabels_test, \n",
    "                                                                y_pred=y_pred, \n",
    "                                                                tranquil=tr_test, \n",
    "                                                                abstain=NLABEL,\n",
    "                                                                dnn=False)             \n",
    "            df1 = pd.DataFrame({'epochs': DNN_EPOCHS,\n",
    "                            'network_seed': NETWORK_SEED, \n",
    "                            'np_seed': NP_SEED, \n",
    "                            'app_type':app, \n",
    "                            'setpoint': setpoint, \n",
    "                            'frac_abstain': frac_abstain, \n",
    "                            'coverage':100.*(1.-frac_abstain), \n",
    "                            'acc': acc,\n",
    "                            'acc_tr':acc_tr,\n",
    "                            'acc_ntr':acc_ntr,\n",
    "                            'n_cover':n_cover,\n",
    "                            'n_tr':n_tr,\n",
    "                            'n_tr_corr':n_tr_corr,\n",
    "                            'n_corr':n_corr,\n",
    "                            'frac_tr':n_tr/n_cover,\n",
    "                            'frac_corr_tr':n_tr_corr/n_corr,\n",
    "                            'acc_portion_tr':n_tr_corr/n_cover,\n",
    "                            'acc_portion_ntr':(n_corr-n_tr_corr)/n_cover,                                \n",
    "                            'perf_frac_tr':np.minimum( 1., np.sum(tr_test)/ n_cover)\n",
    "                           },index=[0])                \n",
    "            df_noabs = df_noabs.append(df1,ignore_index = True)\n",
    "            \n",
    "#----------------------------------------------------------            \n",
    "savename = (DATA_NAME\n",
    "           + '_' + LOSS\n",
    "           + '_npSeed'\n",
    "           + str(NP_SEED)\n",
    "           + '_noAbstain' \n",
    "           )\n",
    "df.to_pickle('predictions/' + savename + '.pkl')\n",
    "\n",
    "plots.plot_stats_comparisons(df_noabs, savename, lines=True, shades=False)\n",
    "plt.savefig('figures/summary_plots/' \n",
    "            + '/statsComparisons_noAbstain_' \n",
    "            + savename\n",
    "            +'.png',dpi=dpiFig)            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at softmax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_dic = {\n",
    "#                 'DNN':'', \n",
    "                'DAC':'', \n",
    "#                 'DNN-DNN':'_postDNN-DNN', \n",
    "#                 'DAC-DNN':'_postDAC-DNN', \n",
    "#                 'ORACLE':'_oracle', \n",
    "#                 'SELENE':'_selene'\n",
    "               }\n",
    "abstain_setpoint = (.6,)#np.around(np.arange(0., 1.01, .01), 3)\n",
    "seed_vector = (19,)#np.arange(0,50)\n",
    "\n",
    "df = pd.DataFrame(columns=('epochs',\n",
    "                               'network_seed',\n",
    "                               'np_seed',\n",
    "                               'app_type',\n",
    "                               'setpoint',\n",
    "                               'frac_abstain',\n",
    "                               'coverage',\n",
    "                               'acc',\n",
    "                               'acc_tr',\n",
    "                               'acc_ntr',\n",
    "                               'n_cover',\n",
    "                               'n_tr',\n",
    "                               'n_tr_corr',\n",
    "                               'n_corr',\n",
    "                               'frac_tr',                               \n",
    "                               'frac_corr_tr',\n",
    "                               'acc_portion_tr',\n",
    "                               'acc_portion_ntr',\n",
    "                               'perf_frac_tr',                               \n",
    "                              )) \n",
    "curr_seed = -999\n",
    "for NETWORK_SEED in seed_vector:  \n",
    "        \n",
    "    for setpoint in abstain_setpoint:\n",
    "        for app in approach_dic.keys():\n",
    "\n",
    "            #-------------------\n",
    "            # get model names\n",
    "            if(app=='DNN' or app=='ORACLE' or app=='SELENE'):\n",
    "                EXP_NAME = get_exp_name(loss = 'DNN', data_name=DATA_NAME, extra_text=approach_dic[app])\n",
    "            elif(app=='DAC'):\n",
    "                EXP_NAME = get_exp_name(loss = LOSS, data_name=DATA_NAME, extra_text = approach_dic[app])\n",
    "            elif(app=='DNN-DNN' or app=='DAC-DNN'):\n",
    "                EXP_NAME = get_exp_name(loss = 'DNN', data_name=DATA_NAME, extra_text=approach_dic[app])\n",
    "                i = EXP_NAME.find('prNoise')\n",
    "                EXP_NAME = EXP_NAME[:i] + 'abstSetpoint' + str(setpoint) + '_' + EXP_NAME[i:]\n",
    "            else:\n",
    "                raise ValueError('no such approach')\n",
    "            model_file = 'saved_models/model_' +  EXP_NAME + '.h5'\n",
    "            \n",
    "            #check for the model file, skip if it does not exist\n",
    "            if(os.path.exists(model_file)==False):\n",
    "                continue\n",
    "            if(curr_seed!=NETWORK_SEED):\n",
    "                print('network seed ' + str(NETWORK_SEED) + ' of ' + str(seed_vector[-1]))\n",
    "                curr_seed = NETWORK_SEED\n",
    "            \n",
    "            if(app=='DAC'):\n",
    "                DAC_model.load_weights(model_file)\n",
    "                y_pred = DAC_model.predict(X_test_std)\n",
    "                abst = np.argmax(y_pred,axis=-1)\n",
    "                frac_abstain = len(np.where(abst==NLABEL)[0])/np.shape(y_pred)[0]  # compute abstention fraction\n",
    "                acc, acc_tr, acc_ntr, n_cover, n_tr, n_tr_corr, n_corr = get_acc_stats(onehotlabels=onehotlabels_test, \n",
    "                                                                    y_pred=y_pred, \n",
    "                                                                    tranquil=tr_test, \n",
    "                                                                    abstain=NLABEL,\n",
    "                                                                    dnn=False)             \n",
    "                df1 = pd.DataFrame({'epochs': DNN_EPOCHS,\n",
    "                                'network_seed': NETWORK_SEED, \n",
    "                                'np_seed': NP_SEED, \n",
    "                                'app_type':app, \n",
    "                                'setpoint': setpoint, \n",
    "                                'frac_abstain': frac_abstain, \n",
    "                                'coverage':100.*(1.-frac_abstain), \n",
    "                                'acc': acc,\n",
    "                                'acc_tr':acc_tr,\n",
    "                                'acc_ntr':acc_ntr,\n",
    "                                'n_cover':n_cover,\n",
    "                                'n_tr':n_tr,\n",
    "                                'n_tr_corr':n_tr_corr,\n",
    "                                'n_corr':n_corr,\n",
    "                                'frac_tr':n_tr/n_cover,\n",
    "                                'frac_corr_tr':n_tr_corr/n_corr,\n",
    "                                'acc_portion_tr':n_tr_corr/n_cover,\n",
    "                                'acc_portion_ntr':(n_corr-n_tr_corr)/n_cover,                                    \n",
    "                                'perf_frac_tr':np.minimum( 1., np.sum(tr_test)/ n_cover)\n",
    "                               },index=[0])                \n",
    "                df = df.append(df1,ignore_index = True)\n",
    "            else:    \n",
    "                DNN_model.load_weights(model_file)\n",
    "                y_pred = DNN_model.predict(X_test_std)                \n",
    "                acc, acc_tr, acc_ntr, n_cover, n_tr, n_tr_corr, n_corr = get_acc_stats(onehotlabels=onehotlabels_test, \n",
    "                                                                                       y_pred=y_pred,\n",
    "                                                                                       tranquil=tr_test,\n",
    "                                                                                       abstain=setpoint,\n",
    "                                                                                       dnn=True)       \n",
    "                df1 = pd.DataFrame({'epochs': DAC_EPOCHS,\n",
    "                                'network_seed': NETWORK_SEED, \n",
    "                                'np_seed': NP_SEED, \n",
    "                                'app_type':app, \n",
    "                                'setpoint': setpoint, \n",
    "                                'frac_abstain': setpoint, \n",
    "                                'coverage':100.*(1.-setpoint), \n",
    "                                'acc': acc,\n",
    "                                'acc_tr':acc_tr,\n",
    "                                'acc_ntr':acc_ntr,\n",
    "                                'n_cover':n_cover,\n",
    "                                'n_tr':n_tr,\n",
    "                                'n_tr_corr':n_tr_corr,\n",
    "                                'n_corr':n_corr,\n",
    "                                'frac_tr':n_tr/n_cover,\n",
    "                                'frac_corr_tr':n_tr_corr/n_corr,\n",
    "                                'acc_portion_tr':n_tr_corr/n_cover,\n",
    "                                'acc_portion_ntr':(n_corr-n_tr_corr)/n_cover,\n",
    "                                'perf_frac_tr':np.minimum( 1., np.sum(tr_test)/ n_cover)\n",
    "                               },index=[0])\n",
    "                df = df.append(df1,ignore_index = True)\n",
    "                \n",
    "# make logits dataframe                \n",
    "df_logits = pd.DataFrame(columns=('max_logit',\n",
    "                                  'pred_label',\n",
    "                                  'true_label'\n",
    "                                 )\n",
    "                        )\n",
    "pred_label = np.argmax(y_pred,axis=-1)\n",
    "df_logits['pred_label'] = pred_label\n",
    "\n",
    "max_logit = np.max(y_pred,axis=-1)\n",
    "df_logits['max_logit'] = max_logit\n",
    "\n",
    "true_label = np.argmax(onehotlabels_test,axis=-1)\n",
    "df_logits['true_label'] = true_label\n",
    "\n",
    "df_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cmap = palettable.cartocolors.qualitative.Vivid_10.mpl_colors\n",
    "inc = .05\n",
    "xbins = np.arange(-inc/2,1.+inc/2,inc)\n",
    "\n",
    "plt.figure(figsize=(4*4,8))\n",
    "for label in np.arange(0,NLABEL+1):\n",
    "\n",
    "    clr = colors[1]\n",
    "    if(label==NLABEL):\n",
    "        clr = colors[0]\n",
    "    \n",
    "    data_plot = df_logits[df_logits['pred_label']==label]\n",
    "    plt.subplot(3,4,label+1)\n",
    "    sns.histplot(data_plot, x=\"max_logit\", element=\"step\", bins=xbins, legend=False, color=clr)\n",
    "    plt.xlim(0,1.0)\n",
    "    plt.xlabel('softmax output')\n",
    "    plt.title('predicted label = ' + str(label))\n",
    "    if(label==NLABEL):\n",
    "        plt.title('predicted label = abstention class')\n",
    "plt.subplot(3,4,12)\n",
    "plt.text(.1,.4,DATA_NAME+'\\nsetpoint = ' + str(setpoint), horizontalalignment='left', fontsize=10)\n",
    "plt.axis('off')\n",
    "\n",
    "# #-----------------------------\n",
    "plt.tight_layout()\n",
    "save_name = DATA_NAME + '_setpoint' + str(setpoint)\n",
    "plt.savefig('figures/summary_plots/' \n",
    "            'logit_histograms_'\n",
    "            + save_name\n",
    "            +'.png',dpi=dpiFig)  \n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
